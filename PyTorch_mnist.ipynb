{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch test script.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nOE2RFhY-DAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For colab\n",
        "!pip install https://download.pytorch.org/whl/cu90/torch-1.0.0-cp36-cp36m-win_amd64.whl\n",
        "!pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8WOxXRH-U5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95b9a98c-461e-4e1b-e8a2-590a41896fe1"
      },
      "cell_type": "code",
      "source": [
        "# If return 'True', GPU is available on the current environment\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e97b1d1f-f5dc-49ce-c5e7-2e703a4f3e79",
        "id": "zAnC2W0VSNdx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "# Run script-based by copying this cell to .py\n",
        "# Based from https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import time\n",
        "\n",
        "class myArgs():\n",
        "  def __init__(self):\n",
        "    self.batch_size = 64         # Training batch size\n",
        "    self.test_batch_size = 1000  # Test batch size\n",
        "    self.epochs = 10             # Epochs\n",
        "    self.lr = 0.01               # Learning rate\n",
        "    self.no_cuda = False         # Force to not use cuda(GPU)\n",
        "    self.seed = 1                # Random seed\n",
        "    self.log_interval = 0        # Log progress(#batch interval) during training\n",
        "    self.save_model = False      # Save model after finish training\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if args.log_interval > 0 and batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "def main():\n",
        "    # Training settings\n",
        "    args = myArgs()\n",
        "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        print('==== Epoch {} ===='.format(epoch))\n",
        "        ts = time.time()\n",
        "        train(args, model, device, train_loader, optimizer, epoch)\n",
        "        print('Training time: {} s'.format(time.time()-ts))\n",
        "\n",
        "        ts = time.time()\n",
        "        test(args, model, device, test_loader)\n",
        "        print('Test time: {} s'.format(time.time()-ts))\n",
        "\n",
        "        print()\n",
        "\n",
        "    if (args.save_model):\n",
        "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
        "        \n",
        "if __name__ == '__main__':\n",
        "    ts_all = time.time()\n",
        "    main()\n",
        "    print('\\n==== Summary====')\n",
        "    print('Total process time: {:.6f} s'.format(time.time()-ts_all))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "==== Epoch 1 ====\n",
            "Training time: 14.299325704574585 s\n",
            "Test set: Average loss: 0.1677, Accuracy: 9506/10000 (95%)\n",
            "Test time: 1.7624938488006592 s\n",
            "\n",
            "==== Epoch 2 ====\n",
            "Training time: 14.228762149810791 s\n",
            "Test set: Average loss: 0.0999, Accuracy: 9711/10000 (97%)\n",
            "Test time: 1.754887342453003 s\n",
            "\n",
            "==== Epoch 3 ====\n",
            "Training time: 14.275679111480713 s\n",
            "Test set: Average loss: 0.0728, Accuracy: 9773/10000 (98%)\n",
            "Test time: 1.7517683506011963 s\n",
            "\n",
            "==== Epoch 4 ====\n",
            "Training time: 14.080678701400757 s\n",
            "Test set: Average loss: 0.0582, Accuracy: 9822/10000 (98%)\n",
            "Test time: 1.7647950649261475 s\n",
            "\n",
            "==== Epoch 5 ====\n",
            "Training time: 14.256437301635742 s\n",
            "Test set: Average loss: 0.0612, Accuracy: 9810/10000 (98%)\n",
            "Test time: 1.7539665699005127 s\n",
            "\n",
            "==== Epoch 6 ====\n",
            "Training time: 14.263263702392578 s\n",
            "Test set: Average loss: 0.0450, Accuracy: 9854/10000 (99%)\n",
            "Test time: 1.751518964767456 s\n",
            "\n",
            "==== Epoch 7 ====\n",
            "Training time: 14.331619501113892 s\n",
            "Test set: Average loss: 0.0438, Accuracy: 9853/10000 (99%)\n",
            "Test time: 1.7711684703826904 s\n",
            "\n",
            "==== Epoch 8 ====\n",
            "Training time: 14.345444917678833 s\n",
            "Test set: Average loss: 0.0463, Accuracy: 9849/10000 (98%)\n",
            "Test time: 1.764845371246338 s\n",
            "\n",
            "==== Epoch 9 ====\n",
            "Training time: 14.325400352478027 s\n",
            "Test set: Average loss: 0.0345, Accuracy: 9891/10000 (99%)\n",
            "Test time: 1.7607274055480957 s\n",
            "\n",
            "==== Epoch 10 ====\n",
            "Training time: 14.259474754333496 s\n",
            "Test set: Average loss: 0.0388, Accuracy: 9870/10000 (99%)\n",
            "Test time: 1.7499713897705078 s\n",
            "\n",
            "\n",
            "==== Summary====\n",
            "Total process time: 166.408824 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
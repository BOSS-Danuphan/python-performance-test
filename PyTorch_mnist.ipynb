{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch test script - mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nOE2RFhY-DAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For colab\n",
        "!pip install https://download.pytorch.org/whl/cu90/torch-1.0.0-cp36-cp36m-win_amd64.whl\n",
        "!pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8WOxXRH-U5s",
        "colab_type": "code",
        "outputId": "5ecf2908-ab93-4aa0-80e8-8070c7285a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# If return 'True', GPU is available on the current environment\n",
        "import torch\n",
        "print('Use Cuda:', torch.cuda.is_available())\n",
        "print('#GPUs:', torch.cuda.device_count())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use Cuda: True\n",
            "#GPUs: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "041fbcb3-9c76-40fb-faf2-b20f5dd203d7",
        "id": "zAnC2W0VSNdx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "cell_type": "code",
      "source": [
        "# Run script-based by copying this cell to .py\n",
        "# Based from https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import time\n",
        "\n",
        "class myArgs():\n",
        "  def __init__(self):\n",
        "    self.batch_size = 64         # Training batch size\n",
        "    self.test_batch_size = 1000  # Test batch size\n",
        "    self.epochs = 10             # Epochs\n",
        "    self.lr = 0.01               # Learning rate\n",
        "    self.no_cuda = False         # Force to not use cuda(GPU)\n",
        "    self.seed = 1                # Random seed\n",
        "    self.log_interval = 0        # Log progress(#batch interval) during training\n",
        "    self.save_model = False      # Save model after finish training\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if args.log_interval > 0 and batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "def main():\n",
        "    # Training settings\n",
        "    args = myArgs()\n",
        "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "    print('Use GPU:', use_cuda)\n",
        "    model = Net()\n",
        "    if use_cuda:\n",
        "      print('#GPUs:', torch.cuda.device_count())\n",
        "      if torch.cuda.device_count() > 1:\n",
        "          model = nn.DataParallel(model)\n",
        "    model.to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        print('==== Epoch {} ===='.format(epoch))\n",
        "        ts = time.time()\n",
        "        train(args, model, device, train_loader, optimizer, epoch)\n",
        "        print('Training time: {} s'.format(time.time()-ts))\n",
        "\n",
        "        ts = time.time()\n",
        "        test(args, model, device, test_loader)\n",
        "        print('Test time: {} s'.format(time.time()-ts))\n",
        "\n",
        "        print()\n",
        "\n",
        "    if (args.save_model):\n",
        "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
        "        \n",
        "if __name__ == '__main__':\n",
        "    ts_all = time.time()\n",
        "    main()\n",
        "    print('\\n==== Summary====')\n",
        "    print('Total process time: {:.6f} s'.format(time.time()-ts_all))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use GPU: True\n",
            "#GPUs: 1\n",
            "==== Epoch 1 ====\n",
            "Training time: 15.230961561203003 s\n",
            "Test set: Average loss: 0.1675, Accuracy: 9501/10000 (95%)\n",
            "Test time: 1.9964420795440674 s\n",
            "\n",
            "==== Epoch 2 ====\n",
            "Training time: 15.360131978988647 s\n",
            "Test set: Average loss: 0.0999, Accuracy: 9707/10000 (97%)\n",
            "Test time: 1.978642463684082 s\n",
            "\n",
            "==== Epoch 3 ====\n",
            "Training time: 15.384657621383667 s\n",
            "Test set: Average loss: 0.0724, Accuracy: 9774/10000 (98%)\n",
            "Test time: 1.9669594764709473 s\n",
            "\n",
            "==== Epoch 4 ====\n",
            "Training time: 15.373796463012695 s\n",
            "Test set: Average loss: 0.0581, Accuracy: 9822/10000 (98%)\n",
            "Test time: 1.9704499244689941 s\n",
            "\n",
            "==== Epoch 5 ====\n",
            "Training time: 15.47372055053711 s\n",
            "Test set: Average loss: 0.0614, Accuracy: 9810/10000 (98%)\n",
            "Test time: 1.942704439163208 s\n",
            "\n",
            "==== Epoch 6 ====\n",
            "Training time: 15.282972812652588 s\n",
            "Test set: Average loss: 0.0450, Accuracy: 9852/10000 (99%)\n",
            "Test time: 1.978839635848999 s\n",
            "\n",
            "==== Epoch 7 ====\n",
            "Training time: 15.22230577468872 s\n",
            "Test set: Average loss: 0.0436, Accuracy: 9849/10000 (98%)\n",
            "Test time: 1.9196224212646484 s\n",
            "\n",
            "==== Epoch 8 ====\n",
            "Training time: 15.297876596450806 s\n",
            "Test set: Average loss: 0.0460, Accuracy: 9850/10000 (98%)\n",
            "Test time: 2.00311017036438 s\n",
            "\n",
            "==== Epoch 9 ====\n",
            "Training time: 15.208472967147827 s\n",
            "Test set: Average loss: 0.0345, Accuracy: 9890/10000 (99%)\n",
            "Test time: 1.9538531303405762 s\n",
            "\n",
            "==== Epoch 10 ====\n",
            "Training time: 15.193751573562622 s\n",
            "Test set: Average loss: 0.0388, Accuracy: 9868/10000 (99%)\n",
            "Test time: 1.928208351135254 s\n",
            "\n",
            "\n",
            "==== Summary====\n",
            "Total process time: 175.183178 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}